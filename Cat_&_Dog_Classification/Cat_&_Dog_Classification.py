# -*- coding: utf-8 -*-
"""Lab_2_Cats_vs_Dogs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qt4ofqN5AVnuzdG6t7JXIv3VHUSVPwc8

# Lab 2: Cats vs Dogs

**Deadline**: Oct 8, 11:59pm

**Late Penalty**: There is a penalty-free grace period of one hour past the deadline. Any work that is submitted between 1 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.

**Marking TA**: Tinglin (Francis) Duan

This lab is partially based on an assignment developed by Prof. Jonathan Rose and Harris Chan.

In this lab, you will train a convolutional neural network to classify an image 
into one of two classes: "cat" or "dog". The code for the neural networks 
you train will be written for you, and you are not (yet!) expected
to understand all provided code. However, by the end of the lab,
you should be able to:

1. Understand at a high level the training loop for a machine learning model.
2. Understand the distinction between training, validation, and test data.
3. The concepts of overfitting and underfitting.
4. Investigate how different hyperparameters, such as learning rate and batch size, affect the success of training.
5. Compare an ANN (aka Multi-Layer Perceptron) with a CNN.

### What to submit

Submit a PDF file containing all your code, outputs, and write-up
from parts 1-5. You can produce a PDF of your Google Colab file by
going to **File > Print** and then save as PDF. The Colab instructions
has more information.

**Do not submit any other files produced by your code.**

Include a link to your colab file in your submission.

Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission. 

With Colab, you can export a PDF file using the menu option
`File -> Print` and save as PDF file. **Adjust the scaling to ensure that the text is not cutoff at the margins.**

## Colab Link

Include a link to your colab file here

Colab Link: https://drive.google.com/file/d/1Qt4ofqN5AVnuzdG6t7JXIv3VHUSVPwc8/view?usp=sharing
"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms

"""## Part 0. Helper Functions

We will be making use of the following helper functions. You will be asked to look
at and possibly modify some of these, but you are not expected to understand all of them.

You should look at the function names and read the docstrings. If you are curious, come back and explore the code *after* making some progress on the lab.
"""

###############################################################################
# Data Loading

def get_relevant_indices(dataset, classes, target_classes):
    """ Return the indices for datapoints in the dataset that belongs to the
    desired target classes, a subset of all possible classes.

    Args:
        dataset: Dataset object
        classes: A list of strings denoting the name of each class
        target_classes: A list of strings denoting the name of desired classes
                        Should be a subset of the 'classes'
    Returns:
        indices: list of indices that have labels corresponding to one of the
                 target classes
    """
    indices = []
    for i in range(len(dataset)):
        # Check if the label is in the target classes
        # dataset[i][1] will return a number (index) representing the class of the i-th set of data in datasets
        label_index = dataset[i][1] # ex. 3
        label_class = classes[label_index] # ex: 'cat'
        if label_class in target_classes:
            indices.append(i)
    return indices

def get_data_loader(target_classes, batch_size):
    """ Loads images of cats and dogs, splits the data into training, validation
    and testing datasets. Returns data loaders for the three preprocessed datasets.

    Args:
        target_classes: A list of strings denoting the name of the desired
                        classes. Should be a subset of the argument 'classes'
        batch_size: A int representing the number of samples per batch
    
    Returns:
        train_loader: iterable training dataset organized according to batch size
        val_loader: iterable validation dataset organized according to batch size
        test_loader: iterable testing dataset organized according to batch size
        classes: A list of strings denoting the name of each class
    """

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    ########################################################################
    # The output of torchvision datasets are PILImage images of range [0, 1].
    # We transform them to Tensors of normalized range [-1, 1].
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    # Load CIFAR10 training data
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform)
    # Get the list of indices to sample from
    relevant_indices = get_relevant_indices(trainset, classes, target_classes)
    
    # Split into train and validation
    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling
    np.random.shuffle(relevant_indices)
    split = int(len(relevant_indices) * 0.8) #split at 80%
    
    # split into training and validation indices
    relevant_train_indices, relevant_val_indices = relevant_indices[:split], relevant_indices[split:]  
    train_sampler = SubsetRandomSampler(relevant_train_indices)
    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                               num_workers=1, sampler=train_sampler)
    val_sampler = SubsetRandomSampler(relevant_val_indices)
    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              num_workers=1, sampler=val_sampler)
    # Load CIFAR10 testing data
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform)
    # Get the list of indices to sample from
    relevant_test_indices = get_relevant_indices(testset, classes, target_classes)
    test_sampler = SubsetRandomSampler(relevant_test_indices)
    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                             num_workers=1, sampler=test_sampler)
    return train_loader, val_loader, test_loader, classes

###############################################################################
# Training
def get_model_name(name, batch_size, learning_rate, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values

    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(name,
                                                   batch_size,
                                                   learning_rate,
                                                   epoch)
    return path

def normalize_label(labels):
    """
    Given a tensor containing 2 possible values, normalize this to 0/1

    Args:
        labels: a 1D tensor containing two possible scalar values
    Returns:
        A tensor normalize to 0/1 value
    """
    max_val = torch.max(labels)
    min_val = torch.min(labels)
    norm_labels = (labels - min_val)//(max_val - min_val)
    return norm_labels

def evaluate(net, loader, criterion):
    """ Evaluate the network on the validation set.

     Args:
         net: PyTorch neural network object
         loader: PyTorch data loader for the validation set
         criterion: The loss function
     Returns:
         err: A scalar for the avg classification error over the validation set
         loss: A scalar for the average loss function over the validation set
     """
    total_loss = 0.0
    total_err = 0.0
    total_epoch = 0
    for i, data in enumerate(loader, 0):
        inputs, labels = data
        labels = normalize_label(labels)  # Convert labels to 0/1
        outputs = net(inputs)
        loss = criterion(outputs, labels.float())
        corr = (outputs > 0.0).squeeze().long() != labels
        total_err += int(corr.sum())
        total_loss += loss.item()
        total_epoch += len(labels)
    err = float(total_err) / total_epoch
    loss = float(total_loss) / (i + 1)
    return err, loss

###############################################################################
# Training Curve
def plot_training_curve(path):
    """ Plots the training curve for a model run, given the csv files
    containing the train/validation error/loss.

    Args:
        path: The base path of the csv files produced during training
    """
    import matplotlib.pyplot as plt
    train_err = np.loadtxt("{}_train_err.csv".format(path))
    val_err = np.loadtxt("{}_val_err.csv".format(path))
    train_loss = np.loadtxt("{}_train_loss.csv".format(path))
    val_loss = np.loadtxt("{}_val_loss.csv".format(path))
    plt.title("Train vs Validation Error")
    n = len(train_err) # number of epochs
    plt.plot(range(1,n+1), train_err, label="Train")
    plt.plot(range(1,n+1), val_err, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend(loc='best')
    plt.show()
    plt.title("Train vs Validation Loss")
    plt.plot(range(1,n+1), train_loss, label="Train")
    plt.plot(range(1,n+1), val_loss, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

"""## Part 1. Visualizing the Data [7 pt]

We will make use of some of the CIFAR-10 data set, which consists of 
colour images of size 32x32 pixels belonging to 10 categories. You can
find out more about the dataset at https://www.cs.toronto.edu/~kriz/cifar.html

For this assignment, we will only be using the cat and dog categories. 
We have included code that automatically downloads the dataset the 
first time that the main script is run.
"""

# This will download the CIFAR-10 dataset to a folder called "data"
# the first time you run this code.
train_loader, val_loader, test_loader, classes = get_data_loader(
    target_classes=["cat", "dog"], 
    batch_size=1) # One image per batch

"""### Part (a) -- 1 pt

Visualize some of the data by running the code below.
Include the visualization in your writeup.

(You don't need to submit anything else.)
"""

import matplotlib.pyplot as plt

k = 0
for images, labels in train_loader:
    # since batch_size = 1, there is only 1 image in `images`
    image = images[0]
    # place the colour channel at the end, instead of at the beginning
    img = np.transpose(image, [1,2,0])
    # normalize pixel intensity values to [0, 1]
    img = img / 2 + 0.5
    plt.subplot(3, 5, k+1)
    plt.axis('off')
    plt.imshow(img)

    k += 1
    if k > 14:
        break

"""### Part (b) -- 3 pt

How many training examples do we have for the combined `cat` and `dog` classes? 
What about validation examples? 
What about test examples?
"""

#num of training examples for cat and dog classes
print("The number of training examples are: ", len(train_loader))

#num of validation examples
print("The number of validation examples are: ", len(val_loader))

#num of test examples
print("The number of test examples are: ", len(test_loader))

"""### Part (c) -- 3pt

Why do we need a validation set when training our model? What happens if we judge the 
performance of our models using the training set loss/error instead of the validation
set loss/error?

####Answer to Part (c):
We need a validation set when training our model because we want to determine how well the model will perform on data it has not been trained on. The model has used the training data as a basis for determining optimal weights that allow for the most accurate prediction. However, in order to ensure that the model has not overfit the training data (ie. simply memorized the training data and expected outputs instead of acquiring ways to observe patterns in the data that lead to an informed decision), we must observe how well it can make predictions on data it has not seen before. If we judge the performance of our model using only the training loss/error, we have no way of knowing if the model is improving because it is able to identify key features in the input data that allows it to output the correct result or if the model is finetuning the parameters to only fit the training data. If it is the latter case, the model will not be generalized enough to perform well on data that was not used during training. Thus, validation data provides a good indicator of model performance and allows us to make adjustments to the hyperparameters accordingly to improve the model.

## Part 2. Training [15 pt]

We define two neural networks, a `LargeNet` and `SmallNet`.
We'll be training the networks in this section.

You won't understand fully what these networks are doing until
the next few classes, and that's okay. For this assignment, please
focus on learning how to train networks, and how hyperparameters affect
training.
"""

class LargeNet(nn.Module):
    def __init__(self):
        super(LargeNet, self).__init__()
        self.name = "large"
        self.conv1 = nn.Conv2d(3, 5, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(5, 10, 5)
        self.fc1 = nn.Linear(10 * 5 * 5, 32)
        self.fc2 = nn.Linear(32, 1)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 10 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        x = x.squeeze(1) # Flatten to [batch_size]
        return x

class SmallNet(nn.Module):
    def __init__(self):
        super(SmallNet, self).__init__()
        self.name = "small"
        self.conv = nn.Conv2d(3, 5, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc = nn.Linear(5 * 7 * 7, 1)

    def forward(self, x):
        x = self.pool(F.relu(self.conv(x)))
        x = self.pool(x)
        x = x.view(-1, 5 * 7 * 7)
        x = self.fc(x)
        x = x.squeeze(1) # Flatten to [batch_size]
        return x

small_net = SmallNet()
large_net = LargeNet()

"""### Part (a) -- 2pt

The methods `small_net.parameters()` and `large_net.parameters()`
produces an iterator of all the trainable parameters of the network.
These parameters are torch tensors containing many scalar values. 

We haven't learned how how the parameters in these high-dimensional
tensors will be used, but we should be able to count the number
of parameters. Measuring the number of parameters in a network is
one way of measuring the "size" of a network.

What is the total number of parameters in `small_net` and in
`large_net`? (Hint: how many numbers are in each tensor?)
"""

num_small_params = 0
num_large_params = 0

for param in small_net.parameters():
    num_small_params += param.numel()

for param in large_net.parameters():
  num_large_params += param.numel()

print(num_small_params)
print(num_large_params)

"""####Answer to Part (a):
The total number of parameters in `small_net` and `large_net` is 386 and 9705, respectively.

### The function train_net

The function `train_net` below takes an untrained neural network (like `small_net` and `large_net`) and
several other parameters. You should be able to understand how this function works.
The figure below shows the high level training loop for a machine learning model:

![alt text](https://github.com/UTNeural/Lab2/blob/master/Diagram.png?raw=true)
"""

def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30):
    ########################################################################
    # Train a classifier on cats vs dogs
    target_classes = ["cat", "dog"]
    ########################################################################
    # Fixed PyTorch random seed for reproducible result
    torch.manual_seed(1000)
    ########################################################################
    # Obtain the PyTorch data loader objects to load batches of the datasets
    train_loader, val_loader, test_loader, classes = get_data_loader(
            target_classes, batch_size)
    ########################################################################
    # Define the Loss function and optimizer
    # The loss function will be Binary Cross Entropy (BCE). In this case we
    # will use the BCEWithLogitsLoss which takes unnormalized output from
    # the neural network and scalar label.
    # Optimizer will be SGD with Momentum.
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)
    ########################################################################
    # Set up some numpy arrays to store the training/test loss/erruracy
    train_err = np.zeros(num_epochs)
    train_loss = np.zeros(num_epochs)
    val_err = np.zeros(num_epochs)
    val_loss = np.zeros(num_epochs)
    ########################################################################
    # Train the network
    # Loop over the data iterator and sample a new batch of training data
    # Get the output from the network, and optimize our loss function.
    start_time = time.time()
    for epoch in range(num_epochs):  # loop over the dataset multiple times
        total_train_loss = 0.0
        total_train_err = 0.0
        total_epoch = 0
        for i, data in enumerate(train_loader, 0):
            # Get the inputs
            inputs, labels = data
            labels = normalize_label(labels) # Convert labels to 0/1
            # Zero the parameter gradients
            optimizer.zero_grad()
            # Forward pass, backward pass, and optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels.float())
            loss.backward()
            optimizer.step()
            # Calculate the statistics
            corr = (outputs > 0.0).squeeze().long() != labels
            total_train_err += int(corr.sum())
            total_train_loss += loss.item()
            total_epoch += len(labels)
        train_err[epoch] = float(total_train_err) / total_epoch
        train_loss[epoch] = float(total_train_loss) / (i+1)
        val_err[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)
        print(("Epoch {}: Train err: {}, Train loss: {} |"+
               "Validation err: {}, Validation loss: {}").format(
                   epoch + 1,
                   train_err[epoch],
                   train_loss[epoch],
                   val_err[epoch],
                   val_loss[epoch]))
        # Save the current model (checkpoint) to a file
        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)
        torch.save(net.state_dict(), model_path)
        
    print('Finished Training')
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Total time elapsed: {:.2f} seconds".format(elapsed_time))
    # Write the train/test loss/err into CSV file for plotting later
    epochs = np.arange(1, num_epochs + 1)
    np.savetxt("{}_train_err.csv".format(model_path), train_err)
    np.savetxt("{}_train_loss.csv".format(model_path), train_loss)
    np.savetxt("{}_val_err.csv".format(model_path), val_err)
    np.savetxt("{}_val_loss.csv".format(model_path), val_loss)

"""### Part (b) -- 1pt

The parameters to the function `train_net` are hyperparameters of our neural network.
We made these hyperparameters easy to modify so that we can tune them later on. 

What are the default values of the parameters `batch_size`, `learning_rate`, 
and `num_epochs`?

####Answer to Part (b):
The default values of `batch_size`, `learning_rate`, and `num_epochs` are 64, 0.01, and 30, respectively. These values are passed into the `train_net()` function directly.

### Part (c) -- 3 pt

What files are written to disk when we call `train_net` with `small_net`, and train for 5 epochs? Provide a list
of all the files written to disk, and what information the files contain.

####Answer to Part (c):
When `train_net` is called with `small_net`, the files written to disk are:

*   model_small_bs64_lr0.01_epoch1
*   model_small_bs64_lr0.01_epoch2
*   model_small_bs64_lr0.01_epoch3
*   model_small_bs64_lr0.01_epoch4
*   model_small_bs64_lr0.01_epoch5
*   model_small_bs64_lr0.01_epoch5_train_err.csv
*   model_small_bs64_lr0.01_epoch5_train_loss.csv
*   model_small_bs64_lr0.01_epoch5_val_err.csv
*   model_small_bs64_lr0.01_epoch5_val_loss.csv

The first 5 files contain the model's `state_dict` for each of the 5 epochs. The `state_dict` is a dictionary which includes the learned parameters for each of the layers of the network and the corresponding tensors they are stored in. Pytorch is able to automatically map each layer of the network to their parameter tensors when `<model_name>.state_dict()` is called. The last 4 files contain the training and validation losses and errors for each epoch. The losses and errors were previously stored inn NumPy arrays and are converted to csv text files using the `np.savetxt()`.

### Part (d) -- 2pt

Train both `small_net` and `large_net` using the function `train_net` and its default parameters.
The function will write many files to disk, including a model checkpoint (saved values of model weights) 
at the end of each epoch.

If you are using Google Colab, you will need to mount Google Drive 
so that the files generated by `train_net` gets saved. We will be using
these files in part (d).
(See the Google Colab tutorial for more information about this.)

Report the total time elapsed when training each network. Which network took longer to train?
Why?
"""

# Since the function writes files to disk, you will need to mount
# your Google Drive. If you are working on the lab locally, you
# can comment out this code.

from google.colab import drive
drive.mount('/content/gdrive')

#training the small network
train_net(small_net)

#training the large network
train_net(large_net)

"""####Answer to Part (d):
The large network took longer to train. This is because the large network has a greater number of layers (an extra convolutional and fully-connected layer) and nodes compared to the small network. This leads to increased time passing data forward through the network as well as computing gradients during backpropagation. There are also more parameters to be updated in the large network during each iteration.

### Part (e) - 2pt

Use the function `plot_training_curve` to display the trajectory of the 
training/validation error and the training/validation loss.
You will need to use the function `get_model_name` to generate the
argument to the `plot_training_curve` function.

Do this for both the small network and the large network. Include both plots
in your writeup.
"""

#plots for small network
model_path_small = get_model_name("small", batch_size=64, learning_rate=0.01, epoch=29)
plot_training_curve(model_path_small)

#plots for large network
model_path_large = get_model_name("large", batch_size=64, learning_rate=0.01, epoch=29)
plot_training_curve(model_path_large)

"""### Part (f) - 5pt

Describe what you notice about the training curve.
How do the curves differ for `small_net` and `large_net`?
Identify any occurences of underfitting and overfitting.

For `small_net` both the training and validation error/loss follow the same relative downward trend and are similar in magnitude. For the `large_net` model, the training and validation error/loss curves for the first few epochs are close together. However, after about 5 epochs, the validation error/loss becomes significantly higher while the training error/loss continues to decrease. This is a symptom of overfitting the training data since the model begins to tune its parameters specifically for the training data and thus performs very well on it. However, the model is no longer transferrable to the validation set and cannot recognize patterns on input data that it was not trained on. Therefore, it cannot map the validation data to the correct output and as the model continues to "memorize" the training data and its outputs, it performs worse on validation data.

## Part 3. Optimization Parameters [12 pt]

For this section, we will work with `large_net` only.

### Part (a) - 3pt

Train `large_net` with all default parameters, except set `learning_rate=0.001`.
Does the model take longer/shorter to train?
Plot the training curve. Describe the effect of *lowering* the learning rate.
"""

# Note: When we re-construct the model, we start the training
# with *random weights*. If we omit this code, the values of
# the weights will still be the previously trained values.
large_net = LargeNet()
train_net(large_net, batch_size=64, learning_rate=0.001, num_epochs=30)

#plotting the large network
path_large = get_model_name("large", batch_size=64, learning_rate=0.001, epoch=29)
plot_training_curve(path_large)

"""####Answer to Part (a):
The model takes more time to train when decreasing the learning rate. Lowering the learning rate evidently helps prevent the large network from overfitting the training data. This is shown by the plotted training and validation curves since the validation error/loss does not diverge from the training error/loss after several epochs as it did before decreasing the learning rate. Furthermore, the training loss curve is smoother. This is because the optimizer is taking smaller steps to decrease loss and thus the loss during each epoch does not fluctuate as much.

### Part (b) - 3pt

Train `large_net` with all default parameters, except set `learning_rate=0.1`. 
Does the model take longer/shorter to train?
Plot the training curve. Describe the effect of *increasing* the learning rate.
"""

#resetting and training the large network
large_net = LargeNet()
train_net(large_net, batch_size=64, learning_rate=0.1, num_epochs=30)

#plotting the large network
path_large = get_model_name("large", batch_size=64, learning_rate=0.1, epoch=29)
plot_training_curve(path_large)

"""####Answer to Part (d):
Increasing the learning rate decreases the time to train the model. Increasing the learning rate also results in more fluctuates in error/loss during each epoch since the optimizer is making larger updates to the parameters each time (taking larger steps to decrease loss). Increasing the learning rate does not help decrease overfitting. Based on the plots, the network is still overfitting the training data since after a few epochs, the validation error/loss diverges from the training error/loss greatly and is a lot higher.

### Part (c) - 3pt

Train `large_net` with all default parameters, including with `learning_rate=0.01`.
Now, set `batch_size=512`. Does the model take longer/shorter to train?
Plot the training curve. Describe the effect of *increasing* the batch size.
"""

#resetting and training the large network
large_net = LargeNet()
train_net(large_net, batch_size=512, learning_rate=0.01, num_epochs=30)

#plotting the large network
path_large = get_model_name("large", batch_size=512, learning_rate=0.01, epoch=29)
plot_training_curve(path_large)

"""####Answer to Part (c):
Increasing the batch size decreases the training time. This is because the number of iterations needed to complete a single epoch decreases. The loss is averaged over a larger batch and thus the the optimizer makes less updates over the 30 epochs to decrease loss. There also appears to be less fluctuation especially in the training/validation loss plot. This is likely due to the loss being averaged over a larger number of training examples, mitigating the effects of outliers on the model parameters, resulting in a smoother curve. It is also evident based on the training/validation plots that overfitting is reduced since the error/loss curves are closer together and validation error/loss is no longer diverging from the training error/loss.

### Part (d) - 3pt

Train `large_net` with all default parameters, including with `learning_rate=0.01`.
Now, set `batch_size=16`. Does the model take longer/shorter to train?
Plot the training curve. Describe the effect of *decreasing* the batch size.
"""

#resetting and training the large network
large_net = LargeNet()
train_net(large_net, batch_size=16, learning_rate=0.01, num_epochs=30)

#plotting the large network
path_large = get_model_name("large", batch_size=16, learning_rate=0.01, epoch=29)
plot_training_curve(path_large)

"""####Answer to Part (d):
The model takes longer to train with a smaller batch size. This is because the number of iterations and number of optimizer updates to decrease loss increases for each epoch. Overfitting is not reduced since the validation and training curves diverge very early on in the training process (validation error/loss is a lot higher than training error/loss and continues to increase while test error/loss decreases).

## Part 4. Hyperparameter Search [6 pt]

### Part (a) - 2pt

Based on the plots from above, choose another set of values for the hyperparameters (network, batch_size, learning_rate)
that you think would help you improve the validation accuracy. Justify your choice.

####Answer to Part (a):
Based on the plots above, it was evident that the large network overfitted the data intially but was capable of producing a lower validation loss by choosing the correct hyperparameters. Based on the above plots, decreasing learning rate and increasing batch size helped to prevent overfitting. I will try to increase validation accuracy by increasing batch size to 512 and choosing a learning rate of 0.001.

### Part (b) - 1pt

Train the model with the hyperparameters you chose in part(a), and include the training curve.
"""

#resetting and training the large network
large = LargeNet()
train_net(large, batch_size=512, learning_rate=0.001, num_epochs=30)

#plotting the large network
path_large = get_model_name("large", batch_size=512, learning_rate=0.001, epoch=29)
plot_training_curve(path_large)

"""### Part (c) - 2pt

Based on your result from Part(a), suggest another set of hyperparameter values to try. 
Justify your choice.

####Answer to Part (c):
Based on the above plots, a learning rate of 0.001 and batch size of 512 were not able to decrease the validation loss from the original model, but overfitting is reduced. In order to further decrease the loss/error, more epochs could be beneficial since this would allow the optimizer to take more steps in decreasing the loss. Additionally, I will try decreasing the batch size from 512 to 128 to allow for more iterations and increasing the learning rate from 0.001 to 0.0045 to make slightly larger updates to the parameters during each iteration in order to decrease loss.

### Part (d) - 1pt

Train the model with the hyperparameters you chose in part(c), and include the training curve.
"""

#resetting and training the large network
better_large = LargeNet()
train_net(better_large, batch_size=128, learning_rate=0.0045, num_epochs=50)

#plotting the large network
path_large = get_model_name("large", batch_size=128, learning_rate=0.0045, epoch=49)
plot_training_curve(path_large)

"""## Part 5. Evaluating the Best Model [15 pt]

### Part (a) - 1pt

Choose the **best** model that you have so far. This means choosing the best model checkpoint,
including the choice of `small_net` vs `large_net`, the `batch_size`, `learning_rate`, 
**and the epoch number**.

Modify the code below to load your chosen set of weights to the model object `net`.
"""

net = LargeNet()
model_path = get_model_name("large", batch_size=128, learning_rate=0.0045, epoch=47)
state = torch.load(model_path)
net.load_state_dict(state)

"""### Part (b) - 2pt

Justify your choice of model from part (a).

####Answer to Part (b):
The model chosen in part (a) is the best model because the combination of hyperparameters fixes the original overfitting issue in the unmodified large network and decreases the validation loss the most compared to previous models. As well, the 48th epoch appeared to decrease validation loss and error the most compared to previous and subsequent epochs, so I loaded the model parameters from that epoch.

### Part (c) - 2pt

Using the code in Part 0, any code from lecture notes, or any code that you write,
compute and report the **test classification error** for your chosen model.
"""

# If you use the `evaluate` function provided in part 0, you will need to 
# set batch_size > 1


#define a new function for to pass test data through the model
def test_net(net, batch_size=512):
    ########################################################################
    #load get training, validation, and test data
    train_loader, val_loader, test_loader, classes = get_data_loader(
    target_classes=["cat", "dog"], 
    batch_size=64)
    criterion = nn.BCEWithLogitsLoss()
    ########################################################################
    # Set up a numpy array to store the test error and validation error
    test_err = np.zeros(1)
    val_err = np.zeros(1)
    ########################################################################
    # Test the network
    # Loop over the data iterator and sample a new batch of testing data
    start_time = time.time()
    total_test_err = 0.0
    #don't need multiple epochs, only need to pass through the entire testing/validation dataset once
    total_epoch = 0
    for i, data in enumerate(test_loader, 0):
        # Get the inputs
        inputs, labels = data
        labels = normalize_label(labels) # Convert labels to 0/1
        # Forward pass
        outputs = net(inputs)
        # Calculate the statistics
        corr = (outputs > 0.0).squeeze().long() != labels
        total_test_err += int(corr.sum())
        total_epoch += len(labels)
    test_err = float(total_test_err) / total_epoch
    val_err, _ = evaluate(net, val_loader, criterion)
    print(("Test err: {}, Val err: {}").format(test_err, val_err))
      
    print('Finished Testing')
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Total time elapsed: {:.2f} seconds".format(elapsed_time))

#call the test_net() function with the best model weights loaded
test_net(net, batch_size=128)

"""### Part (d) - 3pt

How does the test classification error compare with the **validation error**?
Explain why you would expect the test error to be *higher* than the validation error.

####Answer to Part (d):
The test classification error is slightly lower than the validation error. However, we would expect the test error to be higher than the validation error since the test data has not been passed through the model before. This means that the model has not been given the chance to adjust its parameters (either via gradient descent or due to hyperparameter changes) to make better predictions on the test data. Therefore, we would expect the model to have a higher error when predicting on test data.

### Part (e) - 2pt

Why did we only use the test data set at the very end?
Why is it important that we use the test data as little as possible?

###Answer to Part (e):
We only use the test dataset at the very end because in order to determine the true performance accuracy of the model, it should be tested on data that ideally has never been used to modify the model. If the data has been used to make improvements to the model in any way (as is the case with validation or training data), the model's parameters will be tuned to better fit that data and it would no longer be the best indicator on how the model generalizes to make predictions on data that it has never encountered (which is ultimately what the model would be doing in a real-life setting).

### Part (f) - 5pt

How does the your best CNN model compare with an 2-layer ANN model (no convolutional layers) on classifying cat and dog images. You can use a 2-layer ANN architecture similar to what you used in Lab 1. You should explore different hyperparameter settings to determine how well you can do on the validation dataset. Once satisified with the performance, you may test it out on the test data.

Hint: The ANN in lab 1 was applied on greyscale images. The cat and dog images are colour (RGB) and so you will need to flatted and concatinate all three colour layers before feeding them into an ANN.
"""

#Using the 2-layer Pigeon neural network from lab 1
class Pigeon(nn.Module):
    def __init__(self):
        super(Pigeon, self).__init__()
        #create a name for the model
        self.name = "pigeon"
        #change the size of the image from 28*28 to 32*32*3 (3 colour channels)
        self.layer1 = nn.Linear(32 * 32 *3, 30)
        self.layer2 = nn.Linear(30, 1)
    def forward(self, img):
        flattened = img.view(-1, 32 * 32 *3)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        activation2 = activation2.squeeze(1)
        return activation2

#create a model
pigeon = Pigeon()

#pass the model through the training function
train_net(pigeon, batch_size=512, learning_rate=0.01, num_epochs=30)

#saving the best model weights into a new model to be used for testing
best_pigeon = Pigeon()
path = get_model_name("pigeon", batch_size=512, learning_rate=0.01, epoch=29)
state = torch.load(path)
best_pigeon.load_state_dict(state)

#passing the data through the test_net() function
print("\nTesting Results:")
test_net(best_pigeon, batch_size=512)

"""####Answer to Part (f):
The CNN model was able to perform better than the 2-layer ANN since the test error for the ANN was greater than the test error for my best CNN model. The CNN model retains the 2D structure of the images in the convolutional layers which usually allows it to make more accurate predictions.
"""